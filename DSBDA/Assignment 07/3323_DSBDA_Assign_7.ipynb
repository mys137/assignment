{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16894f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Extract Sample document and apply following document preprocessing methods:\n",
    "# Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.\n",
    "# 2. Create representation of document by calculating Term Frequency and Inverse Document \n",
    "# Frequency.'\n",
    "# !pip install nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f714b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114ba529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence Tokenization\n",
    "#Sentence tokenizer breaks text paragraph into sentences.\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "text=\"\"\"Supervised Regression\n",
    "In this case, the problem definition is rather similar to the previous example; the difference \n",
    "relies on the response. In a regression problem, the response y ∈ ℜ, this means the response is \n",
    "real valued. For example, we can develop a model to predict the hourly salary of individuals \n",
    "given the corpus of their CV.\n",
    "Unsupervised Learning\n",
    "Management is often thirsty for new insights. Segmentation models can provide this insight in \n",
    "order for the marketing department to develop products for different segments. A good \n",
    "approach for developing a segmentation model, rather than thinking of algorithms, is to select \n",
    "features that are relevant to the segmentation that is desired.\n",
    "For example, in a telecommunications company, it is interesting to segment clients by their cell \n",
    "phone usage. This would involve disregarding features that have nothing to do with the \n",
    "segmentation objective and including only those that do. In this case, this would be selecting \n",
    "features as the number of SMS used in a month, the number of inbound and outbound minutes, \n",
    "etc.\n",
    "Big Data Analytics -Data Collection:\n",
    "Data collection plays the most important role in the Big Data cycle. The Internet provides \n",
    "almost unlimited sources of data for a variety of topics. The importance of this area depends on \n",
    "the type of business, but traditional industries can acquire a diverse source of external data and \n",
    "combine those with their transactional data.\n",
    "For example, let‘s assume we would like to build a system that recommends restaurants. The \n",
    "first step would be to gather data, in this case, reviews of restaurants from different websites and \n",
    "store them in a database. As we are interested in raw text, and would use that for analytics, it is \n",
    "not that relevant where the data for developing the model would be stored. This may sound \n",
    "contradictory with the big data main technologies, but in order to implement a big data \n",
    "application, we simply need to make it work in real time\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a502f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Supervised Regression\\nIn this case, the problem definition is rather similar to the previous example; the difference \\nrelies on the response.', 'In a regression problem, the response y ∈ ℜ, this means the response is \\nreal valued.', 'For example, we can develop a model to predict the hourly salary of individuals \\ngiven the corpus of their CV.', 'Unsupervised Learning\\nManagement is often thirsty for new insights.', 'Segmentation models can provide this insight in \\norder for the marketing department to develop products for different segments.', 'A good \\napproach for developing a segmentation model, rather than thinking of algorithms, is to select \\nfeatures that are relevant to the segmentation that is desired.', 'For example, in a telecommunications company, it is interesting to segment clients by their cell \\nphone usage.', 'This would involve disregarding features that have nothing to do with the \\nsegmentation objective and including only those that do.', 'In this case, this would be selecting \\nfeatures as the number of SMS used in a month, the number of inbound and outbound minutes, \\netc.', 'Big Data Analytics -Data Collection:\\nData collection plays the most important role in the Big Data cycle.', 'The Internet provides \\nalmost unlimited sources of data for a variety of topics.', 'The importance of this area depends on \\nthe type of business, but traditional industries can acquire a diverse source of external data and \\ncombine those with their transactional data.', 'For example, let‘s assume we would like to build a system that recommends restaurants.', 'The \\nfirst step would be to gather data, in this case, reviews of restaurants from different websites and \\nstore them in a database.', 'As we are interested in raw text, and would use that for analytics, it is \\nnot that relevant where the data for developing the model would be stored.', 'This may sound \\ncontradictory with the big data main technologies, but in order to implement a big data \\napplication, we simply need to make it work in real time']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_text=sent_tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbcb5d",
   "metadata": {},
   "source": [
    "#Word Tokenization\n",
    "#Word tokenizer breaks text paragraph into words.\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_word=word_tokenize(text)\n",
    "print(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a158a951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 185 samples and 363 outcomes>\n"
     ]
    }
   ],
   "source": [
    "#Frequency Distribution\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d67bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19), ('the', 19)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78459760",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fdist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asus\\Documents\\Assignment\\SEM 6\\DSBDA\\DSBDA\\Assignment 07\\3323_DSBDA_Assign_7.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/Assignment/SEM%206/DSBDA/DSBDA/Assignment%2007/3323_DSBDA_Assign_7.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39m# Frequency Distribution Plot\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/Assignment/SEM%206/DSBDA/DSBDA/Assignment%2007/3323_DSBDA_Assign_7.ipynb#ch0000007?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/Assignment/SEM%206/DSBDA/DSBDA/Assignment%2007/3323_DSBDA_Assign_7.ipynb#ch0000007?line=2'>3</a>\u001b[0m fdist\u001b[39m.\u001b[39mplot(\u001b[39m30\u001b[39m,cumulative\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asus/Documents/Assignment/SEM%206/DSBDA/DSBDA/Assignment%2007/3323_DSBDA_Assign_7.ipynb#ch0000007?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fdist' is not defined"
     ]
    }
   ],
   "source": [
    "# Frequency Distribution Plot\n",
    "import matplotlib.pyplot as plt\n",
    "fdist.plot(30,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c50939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yours', 'before', 'aren', \"hadn't\", 'mustn', 'i', 'by', 'y', 're', 'under', 'hadn', 'then', 'further', 'our', 'him', \"wasn't\", 'having', 'through', 'above', 'now', 'themselves', \"shouldn't\", 'she', 'off', 'own', 's', 'his', 'can', \"doesn't\", 'where', 'did', 'are', \"it's\", 'doesn', 'once', 'very', 'so', 'most', 'those', 'nor', 'shouldn', 'does', 'ours', 'than', 'been', 'hers', 'just', 'ain', 'such', 'no', 'itself', \"you're\", 'while', 'each', 'haven', 'that', 'how', 'during', \"isn't\", 'not', 'about', 'do', 'and', 'other', \"haven't\", 'the', 'being', 'won', 'wouldn', 'mightn', 'has', 'in', 'against', 'yourselves', 'whom', 'or', 'll', 'an', 'of', 'didn', 'needn', 'if', 'you', 'until', 'all', 'weren', 'here', 'their', 'me', \"that'll\", 'when', 't', 'myself', 'be', 'after', 'ourselves', 'any', 'm', 'as', 'why', 'on', 'between', 'at', \"didn't\", 'don', 'these', 'am', 'ma', 'will', 'couldn', \"should've\", \"you'll\", 'which', 'down', 'with', 'your', \"don't\", 'they', 'a', \"she's\", 'only', 'isn', 'some', \"wouldn't\", 'for', 'had', 'few', 'them', 'hasn', 'is', 'wasn', 'out', \"you've\", \"aren't\", 'himself', 'what', 'who', 'from', 'theirs', \"needn't\", \"hasn't\", 'shan', 'have', 'same', 'more', 'd', 'this', \"weren't\", 'its', 'herself', 'there', 'up', 'because', 'into', 'too', \"won't\", 'but', 'was', \"couldn't\", \"mightn't\", 'should', 'below', \"you'd\", 'again', \"mustn't\", 'he', 'we', 'doing', 'were', 'her', 'both', 'my', 'it', 've', \"shan't\", 'yourself', 'over', 'to', 'o'}\n"
     ]
    }
   ],
   "source": [
    "#Stopwords\n",
    "#Stopwords considered as noise in the text. \n",
    "#Text may contain stop words such as is, am, are, this, a, an, the, etc.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653ac3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['Supervised', 'Regression', 'In', 'this', 'case', ',', 'the', 'problem', 'definition', 'is', 'rather', 'similar', 'to', 'the', 'previous', 'example', ';', 'the', 'difference', 'relies', 'on', 'the', 'response', '.', 'In', 'a', 'regression', 'problem', ',', 'the', 'response', 'y', '∈', 'ℜ', ',', 'this', 'means', 'the', 'response', 'is', 'real', 'valued', '.', 'For', 'example', ',', 'we', 'can', 'develop', 'a', 'model', 'to', 'predict', 'the', 'hourly', 'salary', 'of', 'individuals', 'given', 'the', 'corpus', 'of', 'their', 'CV', '.', 'Unsupervised', 'Learning', 'Management', 'is', 'often', 'thirsty', 'for', 'new', 'insights', '.', 'Segmentation', 'models', 'can', 'provide', 'this', 'insight', 'in', 'order', 'for', 'the', 'marketing', 'department', 'to', 'develop', 'products', 'for', 'different', 'segments', '.', 'A', 'good', 'approach', 'for', 'developing', 'a', 'segmentation', 'model', ',', 'rather', 'than', 'thinking', 'of', 'algorithms', ',', 'is', 'to', 'select', 'features', 'that', 'are', 'relevant', 'to', 'the', 'segmentation', 'that', 'is', 'desired', '.', 'For', 'example', ',', 'in', 'a', 'telecommunications', 'company', ',', 'it', 'is', 'interesting', 'to', 'segment', 'clients', 'by', 'their', 'cell', 'phone', 'usage', '.', 'This', 'would', 'involve', 'disregarding', 'features', 'that', 'have', 'nothing', 'to', 'do', 'with', 'the', 'segmentation', 'objective', 'and', 'including', 'only', 'those', 'that', 'do', '.', 'In', 'this', 'case', ',', 'this', 'would', 'be', 'selecting', 'features', 'as', 'the', 'number', 'of', 'SMS', 'used', 'in', 'a', 'month', ',', 'the', 'number', 'of', 'inbound', 'and', 'outbound', 'minutes', ',', 'etc', '.', 'Big', 'Data', 'Analytics', '-Data', 'Collection', ':', 'Data', 'collection', 'plays', 'the', 'most', 'important', 'role', 'in', 'the', 'Big', 'Data', 'cycle', '.', 'The', 'Internet', 'provides', 'almost', 'unlimited', 'sources', 'of', 'data', 'for', 'a', 'variety', 'of', 'topics', '.', 'The', 'importance', 'of', 'this', 'area', 'depends', 'on', 'the', 'type', 'of', 'business', ',', 'but', 'traditional', 'industries', 'can', 'acquire', 'a', 'diverse', 'source', 'of', 'external', 'data', 'and', 'combine', 'those', 'with', 'their', 'transactional', 'data', '.', 'For', 'example', ',', 'let', '‘', 's', 'assume', 'we', 'would', 'like', 'to', 'build', 'a', 'system', 'that', 'recommends', 'restaurants', '.', 'The', 'first', 'step', 'would', 'be', 'to', 'gather', 'data', ',', 'in', 'this', 'case', ',', 'reviews', 'of', 'restaurants', 'from', 'different', 'websites', 'and', 'store', 'them', 'in', 'a', 'database', '.', 'As', 'we', 'are', 'interested', 'in', 'raw', 'text', ',', 'and', 'would', 'use', 'that', 'for', 'analytics', ',', 'it', 'is', 'not', 'that', 'relevant', 'where', 'the', 'data', 'for', 'developing', 'the', 'model', 'would', 'be', 'stored', '.', 'This', 'may', 'sound', 'contradictory', 'with', 'the', 'big', 'data', 'main', 'technologies', ',', 'but', 'in', 'order', 'to', 'implement', 'a', 'big', 'data', 'application', ',', 'we', 'simply', 'need', 'to', 'make', 'it', 'work', 'in', 'real', 'time']\n",
      "\n",
      "=======================================\n",
      "\n",
      "Filterd Sentence: ['Supervised', 'Regression', 'In', 'case', ',', 'problem', 'definition', 'rather', 'similar', 'previous', 'example', ';', 'difference', 'relies', 'response', '.', 'In', 'regression', 'problem', ',', 'response', '∈', 'ℜ', ',', 'means', 'response', 'real', 'valued', '.', 'For', 'example', ',', 'develop', 'model', 'predict', 'hourly', 'salary', 'individuals', 'given', 'corpus', 'CV', '.', 'Unsupervised', 'Learning', 'Management', 'often', 'thirsty', 'new', 'insights', '.', 'Segmentation', 'models', 'provide', 'insight', 'order', 'marketing', 'department', 'develop', 'products', 'different', 'segments', '.', 'A', 'good', 'approach', 'developing', 'segmentation', 'model', ',', 'rather', 'thinking', 'algorithms', ',', 'select', 'features', 'relevant', 'segmentation', 'desired', '.', 'For', 'example', ',', 'telecommunications', 'company', ',', 'interesting', 'segment', 'clients', 'cell', 'phone', 'usage', '.', 'This', 'would', 'involve', 'disregarding', 'features', 'nothing', 'segmentation', 'objective', 'including', '.', 'In', 'case', ',', 'would', 'selecting', 'features', 'number', 'SMS', 'used', 'month', ',', 'number', 'inbound', 'outbound', 'minutes', ',', 'etc', '.', 'Big', 'Data', 'Analytics', '-Data', 'Collection', ':', 'Data', 'collection', 'plays', 'important', 'role', 'Big', 'Data', 'cycle', '.', 'The', 'Internet', 'provides', 'almost', 'unlimited', 'sources', 'data', 'variety', 'topics', '.', 'The', 'importance', 'area', 'depends', 'type', 'business', ',', 'traditional', 'industries', 'acquire', 'diverse', 'source', 'external', 'data', 'combine', 'transactional', 'data', '.', 'For', 'example', ',', 'let', '‘', 'assume', 'would', 'like', 'build', 'system', 'recommends', 'restaurants', '.', 'The', 'first', 'step', 'would', 'gather', 'data', ',', 'case', ',', 'reviews', 'restaurants', 'different', 'websites', 'store', 'database', '.', 'As', 'interested', 'raw', 'text', ',', 'would', 'use', 'analytics', ',', 'relevant', 'data', 'developing', 'model', 'would', 'stored', '.', 'This', 'may', 'sound', 'contradictory', 'big', 'data', 'main', 'technologies', ',', 'order', 'implement', 'big', 'data', 'application', ',', 'simply', 'need', 'make', 'work', 'real', 'time']\n"
     ]
    }
   ],
   "source": [
    "#Removing Stopwords\n",
    "#In NLTK for removing stopwords, you need to create a list of stopwords \n",
    "#and filter out your list of tokens from these words.\n",
    "\n",
    "filtered_sent=[]\n",
    "for w in tokenized_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)\n",
    "print(\"Tokenized Sentence:\",tokenized_word)\n",
    "print(\"\\n=======================================\\n\")\n",
    "print(\"Filterd Sentence:\",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd4ffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence: ['Supervised', 'Regression', 'In', 'case', ',', 'problem', 'definition', 'rather', 'similar', 'previous', 'example', ';', 'difference', 'relies', 'response', '.', 'In', 'regression', 'problem', ',', 'response', '∈', 'ℜ', ',', 'means', 'response', 'real', 'valued', '.', 'For', 'example', ',', 'develop', 'model', 'predict', 'hourly', 'salary', 'individuals', 'given', 'corpus', 'CV', '.', 'Unsupervised', 'Learning', 'Management', 'often', 'thirsty', 'new', 'insights', '.', 'Segmentation', 'models', 'provide', 'insight', 'order', 'marketing', 'department', 'develop', 'products', 'different', 'segments', '.', 'A', 'good', 'approach', 'developing', 'segmentation', 'model', ',', 'rather', 'thinking', 'algorithms', ',', 'select', 'features', 'relevant', 'segmentation', 'desired', '.', 'For', 'example', ',', 'telecommunications', 'company', ',', 'interesting', 'segment', 'clients', 'cell', 'phone', 'usage', '.', 'This', 'would', 'involve', 'disregarding', 'features', 'nothing', 'segmentation', 'objective', 'including', '.', 'In', 'case', ',', 'would', 'selecting', 'features', 'number', 'SMS', 'used', 'month', ',', 'number', 'inbound', 'outbound', 'minutes', ',', 'etc', '.', 'Big', 'Data', 'Analytics', '-Data', 'Collection', ':', 'Data', 'collection', 'plays', 'important', 'role', 'Big', 'Data', 'cycle', '.', 'The', 'Internet', 'provides', 'almost', 'unlimited', 'sources', 'data', 'variety', 'topics', '.', 'The', 'importance', 'area', 'depends', 'type', 'business', ',', 'traditional', 'industries', 'acquire', 'diverse', 'source', 'external', 'data', 'combine', 'transactional', 'data', '.', 'For', 'example', ',', 'let', '‘', 'assume', 'would', 'like', 'build', 'system', 'recommends', 'restaurants', '.', 'The', 'first', 'step', 'would', 'gather', 'data', ',', 'case', ',', 'reviews', 'restaurants', 'different', 'websites', 'store', 'database', '.', 'As', 'interested', 'raw', 'text', ',', 'would', 'use', 'analytics', ',', 'relevant', 'data', 'developing', 'model', 'would', 'stored', '.', 'This', 'may', 'sound', 'contradictory', 'big', 'data', 'main', 'technologies', ',', 'order', 'implement', 'big', 'data', 'application', ',', 'simply', 'need', 'make', 'work', 'real', 'time']\n",
      "\n",
      "=======================================\n",
      "\n",
      "Stemmed Sentence: ['supervis', 'regress', 'in', 'case', ',', 'problem', 'definit', 'rather', 'similar', 'previou', 'exampl', ';', 'differ', 'reli', 'respons', '.', 'in', 'regress', 'problem', ',', 'respons', '∈', 'ℜ', ',', 'mean', 'respons', 'real', 'valu', '.', 'for', 'exampl', ',', 'develop', 'model', 'predict', 'hourli', 'salari', 'individu', 'given', 'corpu', 'cv', '.', 'unsupervis', 'learn', 'manag', 'often', 'thirsti', 'new', 'insight', '.', 'segment', 'model', 'provid', 'insight', 'order', 'market', 'depart', 'develop', 'product', 'differ', 'segment', '.', 'a', 'good', 'approach', 'develop', 'segment', 'model', ',', 'rather', 'think', 'algorithm', ',', 'select', 'featur', 'relev', 'segment', 'desir', '.', 'for', 'exampl', ',', 'telecommun', 'compani', ',', 'interest', 'segment', 'client', 'cell', 'phone', 'usag', '.', 'thi', 'would', 'involv', 'disregard', 'featur', 'noth', 'segment', 'object', 'includ', '.', 'in', 'case', ',', 'would', 'select', 'featur', 'number', 'sm', 'use', 'month', ',', 'number', 'inbound', 'outbound', 'minut', ',', 'etc', '.', 'big', 'data', 'analyt', '-data', 'collect', ':', 'data', 'collect', 'play', 'import', 'role', 'big', 'data', 'cycl', '.', 'the', 'internet', 'provid', 'almost', 'unlimit', 'sourc', 'data', 'varieti', 'topic', '.', 'the', 'import', 'area', 'depend', 'type', 'busi', ',', 'tradit', 'industri', 'acquir', 'divers', 'sourc', 'extern', 'data', 'combin', 'transact', 'data', '.', 'for', 'exampl', ',', 'let', '‘', 'assum', 'would', 'like', 'build', 'system', 'recommend', 'restaur', '.', 'the', 'first', 'step', 'would', 'gather', 'data', ',', 'case', ',', 'review', 'restaur', 'differ', 'websit', 'store', 'databas', '.', 'as', 'interest', 'raw', 'text', ',', 'would', 'use', 'analyt', ',', 'relev', 'data', 'develop', 'model', 'would', 'store', '.', 'thi', 'may', 'sound', 'contradictori', 'big', 'data', 'main', 'technolog', ',', 'order', 'implement', 'big', 'data', 'applic', ',', 'simpli', 'need', 'make', 'work', 'real', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "stemmed_words=[]\n",
    "for w in filtered_sent:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "\n",
    "print(\"Filtered Sentence:\",filtered_sent)\n",
    "print(\"\\n=======================================\\n\")\n",
    "print(\"Stemmed Sentence:\",stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374dc9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Word: go\n",
      "Stemmed Word: went\n"
     ]
    }
   ],
   "source": [
    "#Lexicon Normalization\n",
    "#performing stemming and Lemmatization\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "\n",
    "word = \"went\"\n",
    "print(\"Lemmatized Word:\",lem.lemmatize(word,\"v\"))\n",
    "print(\"Stemmed Word:\",stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3ee9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tagging', 'is', 'a', 'kind', 'of', 'classification', 'that', 'may', 'be', 'defined', 'as', 'the', 'automatic', 'assignment', 'of', 'description', 'to', 'the', 'tokens', '.']\n"
     ]
    }
   ],
   "source": [
    "#POS Tagging\n",
    "\n",
    "sent = \"Tagging is a kind of classification that may be defined as the automatic assignment of description to the tokens.\"\n",
    "tokens=nltk.word_tokenize(sent)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb4fbb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tagging', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('kind', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('classification', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('defined', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('automatic', 'JJ'),\n",
       " ('assignment', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('description', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('tokens', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a64400e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create representation of document by calculating Term Frequency and Inverse Document \n",
    "# Frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a0af5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = ['data science is one of the most important fields of science',\n",
    "          'this is one of the best data science courses',\n",
    "          'data scientists analyze data' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6eaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_idf_model  = TfidfVectorizer()\n",
    "tf_idf_vector = tr_idf_model.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13efb580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x14 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3c01f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.18952581 0.32089509 0.32089509\n",
      "  0.24404899 0.32089509 0.48809797 0.24404899 0.48809797 0.\n",
      "  0.24404899 0.        ]\n",
      " [0.         0.40029393 0.40029393 0.23642005 0.         0.\n",
      "  0.30443385 0.         0.30443385 0.30443385 0.30443385 0.\n",
      "  0.30443385 0.40029393]\n",
      " [0.54270061 0.         0.         0.64105545 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54270061\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_array = tf_idf_vector.toarray()\n",
    "\n",
    "print(tf_idf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32ffa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['analyze', 'best', 'courses', 'data', 'fields', 'important', 'is', 'most', 'of', 'one', 'science', 'scientists', 'the', 'this']\n"
     ]
    }
   ],
   "source": [
    "words_set = tr_idf_model.get_feature_names()\n",
    "\n",
    "print(words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733e878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyze</th>\n",
       "      <th>best</th>\n",
       "      <th>courses</th>\n",
       "      <th>data</th>\n",
       "      <th>fields</th>\n",
       "      <th>important</th>\n",
       "      <th>is</th>\n",
       "      <th>most</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>science</th>\n",
       "      <th>scientists</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189526</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.488098</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.488098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.236420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.400294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    analyze      best   courses      data    fields  important        is  \\\n",
       "0  0.000000  0.000000  0.000000  0.189526  0.320895   0.320895  0.244049   \n",
       "1  0.000000  0.400294  0.400294  0.236420  0.000000   0.000000  0.304434   \n",
       "2  0.542701  0.000000  0.000000  0.641055  0.000000   0.000000  0.000000   \n",
       "\n",
       "       most        of       one   science  scientists       the      this  \n",
       "0  0.320895  0.488098  0.244049  0.488098    0.000000  0.244049  0.000000  \n",
       "1  0.000000  0.304434  0.304434  0.304434    0.000000  0.304434  0.400294  \n",
       "2  0.000000  0.000000  0.000000  0.000000    0.542701  0.000000  0.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf = pd.DataFrame(tf_idf_array, columns = words_set)\n",
    "\n",
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a02e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
